{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "casual-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pyspark\n",
    "from pyspark import SparkContext,SparkConf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nearby-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('C:\\spark-3.2.0-bin-hadoop3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "following-kentucky",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.2.0-bin-hadoop3.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intended-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkConf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "important-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "weighted-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sc.parallelize([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "proprietary-exemption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "decent-advantage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "needed-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-connectivity",
   "metadata": {},
   "source": [
    "# First way to create spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "annual-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName('ishti').setMaster('local')\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "loving-picking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.master', 'local'),\n",
       " ('spark.app.id', 'local-1635254841677'),\n",
       " ('spark.driver.port', '50263'),\n",
       " ('spark.app.name', 'ishti'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.host', 'ADMIN11-PC'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.app.startTime', '1635254841227')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fourth-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-yukon",
   "metadata": {},
   "source": [
    "# 2nd way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "threaded-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "elegant-accident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.port', '50294'),\n",
       " ('spark.driver.host', 'ADMIN11-PC'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.startTime', '1635254842319'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.id', 'local-1635254842706'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.app.name', 'pyspark-shell')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "vocational-weapon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x25542242070>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "received-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acceptable-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext('local','myapp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "numerous-leave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.master', 'local'),\n",
       " ('spark.app.name', 'myapp'),\n",
       " ('spark.driver.host', 'ADMIN11-PC'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.id', 'local-1635254843533'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.startTime', '1635254843343'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.port', '50325')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-disease",
   "metadata": {},
   "source": [
    "# Actions and Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-adventure",
   "metadata": {},
   "source": [
    "In machine learning we interact with data by appliying certain commands like groupby sorting min max cleaning graphing etc. All there are termed as operations. In spark we perform operations via actions and transformations. \n",
    "difference is transformations mainly deal with allotment of data to Resilient distributed dataset (RDD) ie it focuses on the creation of rdd's and does not execute further until an action is performed hence it is termed as lazy operator. While actions result in an output which is fast as compared to conventional working transformations so not result in any kind of output rather they they just allot data to rdd and do not go further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fantastic-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sc.parallelize(['abc','efg','hij','klm','nop','qrs','tuv','wxyz'],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "correct-vehicle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc', 'efg', 'hij', 'klm', 'nop', 'qrs', 'tuv', 'wxyz']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-psychiatry",
   "metadata": {},
   "source": [
    "in general we dont use collect in reality. this is because of 2 reasons:\n",
    "1. spark is mainly used when size of our dataset is usually bigger than the ram size so if we collect data entire data would be thrown to ram which dissolves the purpose of using spark\n",
    "2. m still working on this part...\n",
    "\n",
    "so what do we use to view data here...???\n",
    "like we used head in pandas we use take and we specify the number of values we want to view. try \n",
    "names.take(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "blessed-coach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc', 'efg', 'hij', 'klm', 'nop']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abstract-packaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-chain",
   "metadata": {},
   "source": [
    "# Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "married-participation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'abc': 1,\n",
       "             'efg': 1,\n",
       "             'hij': 1,\n",
       "             'klm': 1,\n",
       "             'nop': 1,\n",
       "             'qrs': 1,\n",
       "             'tuv': 1,\n",
       "             'wxyz': 1})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-level",
   "metadata": {},
   "source": [
    "Glom function\n",
    "1. Creates partition in rdd\n",
    "2. glom helps in accessing elements by means of partition. when we want to view data we generally use take(num)/ take(num)[index] but with glom it becomes more accesible. Check codes below\n",
    "3. its a pipeline rdd\n",
    "4. pyspark does not allow worker to refer to other portions so by using glom worker can access other partitions.. still need to understand this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "competitive-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "no = sc.parallelize([3,2,6,7,2,5,8,3,9,3,6,4,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "prospective-litigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 6, 7, 2, 5, 8, 3, 9, 3, 6, 4, 7]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "silent-sharing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 2, 6, 7, 2, 5, 8, 3, 9, 3, 6, 4, 7]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "organizational-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no.take(3)[2]              #if indes is >= take(num) we will get an error\n",
    "                           #which means we can only see value from that range of take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "short-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-still",
   "metadata": {},
   "source": [
    "it looks same till this point, now lets try a partition in no rdd and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "applicable-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "no = sc.parallelize([3,2,6,7,2,5,8,3,9,3,6,4,7],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "rubber-novelty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 6, 7, 2, 5, 8, 3, 9, 3, 6, 4, 7]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "meaningful-pierre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 2, 6, 7, 2, 5], [8, 3, 9, 3, 6, 4, 7]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-robertson",
   "metadata": {},
   "source": [
    "numslices in argument refers to the number of partition we want in our rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "engaging-leadership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 4, 7]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no.glom().collect()[1][4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "gothic-private",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(no.glom())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-content",
   "metadata": {},
   "source": [
    "# Reduce and Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adapted-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "nos = sc.parallelize([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "broad-union",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "gross-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul(a,b):\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "shared-junior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.reduce(mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "serial-asian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.reduce(lambda a,b:a*2+b*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "amended-processor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.reduce(lambda x,y: x if x>y else y)    #checking for greatest integer in rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "broadband-delight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.reduce(lambda x,y: x if x<y else y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-bookmark",
   "metadata": {},
   "source": [
    "Reduce basically performs same as pandas reduce. it works on the principle of comparison between two variables or by means of two var. obviously since we want a reduce operation which isnt possible by working with one variable. so + * > < and such functions would work well with reduce\n",
    "\n",
    "Now lets see some fold operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "mathematical-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "nos = sc.parallelize([2,3,4])  #default partition value is chosen one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "split-corrections",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "included-recovery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "drawn-coast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.fold(0,lambda a,b:a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ready-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "nos = sc.parallelize([2,3,4],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "rotary-emerald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "casual-meaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2], [3, 4]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "compliant-newport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.fold(1,lambda a,b:a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bigger-balloon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.fold(2, lambda a,b:a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-speaker",
   "metadata": {},
   "source": [
    "nos.fold(arg,func) so arg value is being multiplied with the nos of brackets as per patition\n",
    "1. arg=1 and part=2 ie 3 brackets so 1*3 would get added to total sum\n",
    "2. arg=2 and part=2 ie 3 brackets so 2*3=6 would be added to total sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "medical-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "nos = sc.parallelize([2,3,4],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "organized-transparency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2], [3], [4]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "biological-people",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.fold(3,lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-telephone",
   "metadata": {},
   "source": [
    "lets understand this by doing some other operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "behavioral-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "nos = sc.parallelize([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "electoral-confirmation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "employed-continuity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.fold(0,lambda x,y:x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "forced-kentucky",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.fold(1,lambda x,y:x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "accredited-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.fold(2,lambda x,y:x*y)  #2*3*4=24 and 2fold *2brackets=4 so 24*4=96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-residence",
   "metadata": {},
   "source": [
    "(arg^^(no of brackets))*total is what fold will return in multiplication case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "figured-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "nos = sc.parallelize([2,3,4],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "retired-delhi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2], [3], [4]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "inappropriate-orange",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1944"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.fold(3,lambda x,y:x*y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-research",
   "metadata": {},
   "source": [
    "3^4= 81\n",
    "total = 24\n",
    "o/p = 81*24--> 1944"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-following",
   "metadata": {},
   "source": [
    "Other ways of applying fold.\n",
    "\n",
    "we can use multiply division and other operations as well from operator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "threatened-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = sc.parallelize(np.random.rand(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "thorough-eight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38148337351830364,\n",
       " 0.6382965714292532,\n",
       " 0.9069796756995182,\n",
       " 0.1118109078483076,\n",
       " 0.3591637251081974,\n",
       " 0.01442548007477118,\n",
       " 0.06618036527451532,\n",
       " 0.2381547988025724,\n",
       " 0.9144281796359204,\n",
       " 0.9974606054117435]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "developmental-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "found-framing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6283836828031015"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.fold(1,add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-plastic",
   "metadata": {},
   "source": [
    "Note: All functions applied above belong to action category\n",
    "\n",
    "Further on we ll be seeing transformation operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-timothy",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-uzbekistan",
   "metadata": {},
   "source": [
    "We have two types of transformations namely:\n",
    "1. Narrow\n",
    "2. Wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-cabin",
   "metadata": {},
   "source": [
    "# Narrow transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fantastic-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = sc.parallelize(range(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "packed-quarterly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.collect()  #collect is action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bored-mailing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[38] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.map(lambda x:x*2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "coastal-triangle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.map(lambda x:x*2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-given",
   "metadata": {},
   "source": [
    " 1. map is a transformation function here\n",
    " 2. we can see that it transformed one rdd to another rdd\n",
    " 3. lambda function wont get executed until we apply an action method on top of transformation\n",
    " 4. hence the name lazy operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "hearing-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def into(x):\n",
    "    return x*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "suited-serial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 9, 12, 15]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.map(into).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "sufficient-priest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[41] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.map(into)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "developing-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sc.parallelize(['dom','som','rom','dooo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "sufficient-education",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr.dom', 'Mr.som', 'Mr.rom', 'Mr.dooo']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.map(lambda x: 'Mr.'+x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "painful-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "legitimate-saskatchewan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 3]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda x: range(2,x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "horizontal-titanium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 1, 2, 3]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda y:range(1,y)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "expensive-convergence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 3, 6, 9, 4, 8, 12]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda x:(x,x*2,x*3)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aquatic-vault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 3, 2, 4, 3]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda x:(x,x-1)).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "committed-ordinary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda x:x%2==0).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "boxed-prototype",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dom', 'som', 'rom', 'dooo']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "designed-patient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dom', 'dooo']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.filter(lambda x: 'd' in x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-adoption",
   "metadata": {},
   "source": [
    "map flatmap filter are all transformation functions \n",
    "1. Map keeps the number of partions same as original partition but changes some features of rdd like it wont be similar to the original rdd\n",
    "2. Flatmap can increase or decrease the number of partitions in an rdd in short it performs operations such that ur new rdd will be different from original one interms of size features\n",
    "3. filter will only reduce the number of partitions in an rdd\n",
    "\n",
    "Logic in each function of transformation defines the way we give input to a particular function \n",
    "for eg we cant give a single variable function to flatmap as it wont serve the logic and we cant give a double variable function to filter \n",
    "\n",
    "refer the codes to understand it better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "clinical-enforcement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "peripheral-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "uniform-bacon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnionRDD[53] at union at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.union(nos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "adopted-yemen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 2, 3, 4]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.union(nos).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bearing-translator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.union(num).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "hybrid-token",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 3, 3, 3, 3, 4]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos.sample(True,.4).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-morning",
   "metadata": {},
   "source": [
    "# Wide transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ahead-lawyer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dom', 'som', 'rom', 'dooo']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bibliographic-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_gr = names.groupBy(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "flexible-theorem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d', <pyspark.resultiterable.ResultIterable at 0x255422bc5e0>),\n",
       " ('s', <pyspark.resultiterable.ResultIterable at 0x255422fcb80>),\n",
       " ('r', <pyspark.resultiterable.ResultIterable at 0x255422fc460>)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_gr.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-penguin",
   "metadata": {},
   "source": [
    "what groupby does...?\n",
    "as per the function mentioned above groupby is taking the first element of each variable and naming the grp with that initial. now inside that grp we have those specific variables which have their first letter with that grp name. So basically we have \n",
    "1. grp name as first letter ie: key\n",
    "2. variables as values to those keys\n",
    "\n",
    "So in short we have a key value pair formed. now we ll access that using a for loop\n",
    "\n",
    "Note: This logic is also termed as generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "needed-organizer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d ['dom', 'dooo']\n",
      "s ['som']\n",
      "r ['rom']\n"
     ]
    }
   ],
   "source": [
    "for i,j in names_gr.collect():\n",
    "    print(i,list(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "complete-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = sc.parallelize([2,1,3,8,6,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "peaceful-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = sc.parallelize([5,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "delayed-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_grp3 = aa.groupBy(lambda x:x%3).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "supreme-makeup",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa_grp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-2fcdbefea9c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maa_grp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aa_grp' is not defined"
     ]
    }
   ],
   "source": [
    "for i,j in aa_grp:\n",
    "    print(i,list(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_grp2 = aa.groupBy(lambda x:x%2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in aa_grp2:\n",
    "    print(i,list(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-owner",
   "metadata": {},
   "source": [
    "How is the above code working..?\n",
    "\n",
    "1. values which are divisible are put under 0 key category ie remainder 0\n",
    "2. those which arent and have a remainder are put under 1:key category\n",
    "\n",
    "imply the same logic when we divide by 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.intersection(bb).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.intersection(aa).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.subtract(bb).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.subtract(aa).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = sc.parallelize([2,2,3,3,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-filing",
   "metadata": {},
   "source": [
    "Union Intersection Subtract Distinct\n",
    "1. intersection and union is basically like mathematics sets union and intersection\n",
    "2. Subtract works different\n",
    "if we have aa.subtract(bb) then it looks for all elements of aa in bb and whichever are not common it prints that value. Like intersection of aa and bb but will print remaining elements of aa apart from intersection elements\n",
    "3. distinct gives distinct values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-tragedy",
   "metadata": {},
   "source": [
    "25th OCT: Till now we were using single value in rdd now we will try working with key value pairs in rdd and perform some functions of wide transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize([(1,2),(1,3),(2,3),(3,4),(3,5),(1,2),(2,3),(3,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.lookup(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mapValues(lambda x:x*x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reduceByKey(lambda x,y: x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reduceByKey(max).collect()   # output contains those tuples which have the max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reduceByKey(min).collect()    # output contains those tuples which have the min value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grp = data.groupBy(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grp.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in data_grp.collect():\n",
    "    print(i,list(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grp1 = data.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in data_grp1:\n",
    "    print(i,list(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-median",
   "metadata": {},
   "source": [
    "Can you spot the difference between groupby and groupbykey code above...?\n",
    "\n",
    "When would we use groupbykey or a reducebykey or mapvalue instead of groupby/reduce/map/flatmap...?\n",
    "1. when we have a key value pair in our rdd\n",
    "2. in order to access a key or a value we would specify that via a function and access that respectively like mapvalue means map over values of rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = sc.parallelize([(1,4),(3,2)])\n",
    "dat.flatMapValues(lambda x:range(1,x)).collect()\n",
    "# similar to flatmap as seen previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = sc.parallelize([(2,5),(1,4),(5,1)])\n",
    "data2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.subtractByKey(data2).collect()   \n",
    "# keys of data2 are matched with data and the remaining pairs from data are given as o/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.subtractByKey(data).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.join(data2).collect()    # not clear how this worked...!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.join(data).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rightOuterJoin(data2).collect()     # extended code of join, understand join first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.rightOuterJoin(data).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.leftOuterJoin(data2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-diary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
